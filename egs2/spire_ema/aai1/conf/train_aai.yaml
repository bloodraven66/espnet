# Trained with A40 (48 GB) x 1 GPUs.
encoder: conformer
encoder_conf:
    output_size: 384
    attention_heads: 1
    linear_units: 512
    num_blocks: 8
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.1
    input_layer: linear
    normalize_before: true
    macaron_style: true
    pos_enc_layer_type: "rel_pos"
    selfattention_layer_type: "rel_selfattn"
    activation_type: "swish"
    use_cnn_module:  true
    cnn_module_kernel: 5

decoder: linear
decoder_conf:
    num_output_feats: 12

frontend_conf:
    n_fft: 512
    win_length: 400
    hop_length: 160

seed: 2022
num_workers: 4
batch_type: numel
batch_bins: 8000000
accum_grad: 1
max_epoch: 50
patience: none
init: none
best_model_criterion:
-   - valid
    - cc
    - max
keep_nbest_models: 1
use_amp: true

optim: adam
optim_conf:
    lr: 0.002
    weight_decay: 0.000001
